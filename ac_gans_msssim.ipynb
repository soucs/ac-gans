{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soucs/ac-gans/blob/main/ac_gans_msssim.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "RvXiasFHMCz5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.optim import Adam\n",
        "from torch.nn.functional import one_hot\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import ToTensor, ToPILImage, Normalize, Compose\n",
        "from torchvision.datasets import CIFAR10"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing transforms to apply on data\n",
        "transform = Compose([ToTensor(),\n",
        "                     Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\n",
        "\n",
        "batch_size = 100\n",
        "\n",
        "train = CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "# Create Dataloader\n",
        "train_dl = DataLoader(train, batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTyfuPSm3v-B",
        "outputId": "72a8a1a7-49a9-40a0-dec5-87e4d0d94a18"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 10\n",
        "batch_size = 100\n",
        "latent_size = 100\n",
        "\n",
        "# Function to denormalize [-1,1] -> [0,1]\n",
        "def denorm(x):\n",
        "  out = (x + 1) / 2\n",
        "  return out.clamp(0, 1)\n",
        "\n",
        "# Get random noise input vector (latent_space_randn + one_hot_label)\n",
        "def get_z(classes):\n",
        "  z = torch.randn(batch_size, latent_size)\n",
        "  y = one_hot(classes.reshape(batch_size), num_classes)\n",
        "  z = torch.cat([z, y], dim=1).reshape(-1,110,1,1)\n",
        "  return z"
      ],
      "metadata": {
        "id": "dTpmyI7W32xz"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Discriminator network\n",
        "class Discriminator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Discriminator, self).__init__()\n",
        "    def discriminator_block(inp, out, stride, bn=True):\n",
        "      block = [nn.Conv2d(inp, out, 3, stride, 1), nn.LeakyReLU(0.2, inplace=True), nn.Dropout2d(0.5)]\n",
        "      if bn:\n",
        "        block.append(nn.BatchNorm2d(out, 0.8))\n",
        "      return block\n",
        "    # Common layers\n",
        "    self.common = nn.Sequential(*discriminator_block(3, 16, 2, bn=False),\n",
        "                                *discriminator_block(16, 32, 1),\n",
        "                                *discriminator_block(32, 64, 2),\n",
        "                                *discriminator_block(64, 128, 1),\n",
        "                                *discriminator_block(128, 256, 2),\n",
        "                                *discriminator_block(256, 512, 1))\n",
        "\n",
        "    # Real/Fake classifier layer\n",
        "    self.discrim = nn.Sequential(nn.Linear(512*4*4, 1),\n",
        "                                 nn.Sigmoid())\n",
        "    # Auxiliary classifier (classes) layer\n",
        "    self.auxil = nn.Sequential(nn.Linear(512*4*4, 10),\n",
        "                               nn.Softmax(dim=1))\n",
        "  def forward(self, input): # input = images (batch_size, 3, 32, 32)\n",
        "    hid_out = self.common(input)\n",
        "    hid_out = hid_out.view(hid_out.size(0), -1)\n",
        "    rf_out = self.discrim(hid_out)\n",
        "    aux_out = self.auxil(hid_out)\n",
        "    return rf_out, aux_out\n",
        "\n",
        "# Generator network\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Generator, self).__init__()\n",
        "    def generator_block(inp, out, nonlin='relu', bn=True):\n",
        "      block = [nn.ConvTranspose2d(inp, out, 5, 2, 1)]\n",
        "      if nonlin == 'tanh':\n",
        "        block.append(nn.Tanh())\n",
        "      else:\n",
        "        block.append(nn.ReLU())\n",
        "      if bn:\n",
        "          block.append(nn.BatchNorm2d(out, 0.8))\n",
        "      return block\n",
        "    self.gen = nn.Sequential(*generator_block(110,384),\n",
        "                             *generator_block(384,192),\n",
        "                             *generator_block(192,96),\n",
        "                             *generator_block(96,3, nonlin='tanh', bn=False),\n",
        "                             nn.UpsamplingBilinear2d((32,32)))\n",
        "  def forward(self, input): # input = classes (batch_size)\n",
        "    z = get_z(input) # z = latent space (batch_size, 110, 1, 1)\n",
        "    fake_img = self.gen(z)\n",
        "    return fake_img"
      ],
      "metadata": {
        "id": "hqCXCqPz-PIq"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "D = Discriminator()\n",
        "G = Generator()\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "aux_criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "d_optimizer = Adam(D.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "g_optimizer = Adam(G.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "\n",
        "def train_discriminator(images,classes):\n",
        "    real_labels = torch.ones(batch_size,1)\n",
        "    fake_labels = torch.zeros(batch_size,1)\n",
        "\n",
        "    # Get loss for real/fake and classes with real images\n",
        "    rf_out, aux_out = D(images)\n",
        "    d_loss_real = criterion(rf_out, real_labels)\n",
        "    d_loss_rclass = aux_criterion(aux_out, classes)\n",
        "\n",
        "    # Get loss for real/fake and classes with fake images\n",
        "    fake_images = G(classes)\n",
        "    rf_out, aux_out = D(fake_images)\n",
        "    d_loss_fake = criterion(rf_out, fake_labels)\n",
        "    d_loss_fclass = aux_criterion(aux_out, classes)\n",
        "\n",
        "    # Combine losses\n",
        "    Ls = d_loss_real + d_loss_fake\n",
        "    Lc = d_loss_rclass + d_loss_fclass\n",
        "    d_loss = Lc + Ls\n",
        "\n",
        "    reset_grad()\n",
        "    d_loss.backward()\n",
        "    d_optimizer.step()\n",
        "    return d_loss\n",
        "\n",
        "def train_generator(classes):\n",
        "    real_labels = torch.ones(batch_size,1)\n",
        "\n",
        "    fake_images = G(classes)\n",
        "    rf_out, aux_out = D(fake_images)\n",
        "\n",
        "    # Get loss of real/fake and classes with fake images\n",
        "    g_loss_fake = criterion(rf_out, real_labels)\n",
        "    g_loss_fclass = aux_criterion(aux_out, classes)\n",
        "\n",
        "    # Combine losses\n",
        "    g_loss = g_loss_fake + g_loss_fclass\n",
        "\n",
        "    reset_grad()\n",
        "    g_loss.backward()\n",
        "    g_optimizer.step()\n",
        "    return g_loss\n",
        "\n",
        "def reset_grad():\n",
        "  d_optimizer.zero_grad()\n",
        "  g_optimizer.zero_grad()"
      ],
      "metadata": {
        "id": "T8jEZfHjDyep"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CODE BLOCK FOR SAVING GENERATED IMAGES\n",
        "import os\n",
        "from IPython.display import Image\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "sample_dir = 'samples'\n",
        "if not os.path.exists(sample_dir):\n",
        "    os.makedirs(sample_dir)\n",
        "\n",
        "for i, classes in train_dl:\n",
        "    # sample_vectors = get_z(classes)\n",
        "    break\n",
        "\n",
        "def save_fake_images(index):\n",
        "    fake_images = G(classes)\n",
        "    fake_images = fake_images.reshape(fake_images.size(0), 3, 32, 32)\n",
        "    fake_fname = 'fake_images-{0:0=4d}.png'.format(index)\n",
        "    print('Saving', fake_fname)\n",
        "    save_image(denorm(fake_images), os.path.join(sample_dir, fake_fname), nrow=10)\n",
        "\n",
        "# # Before training\n",
        "save_fake_images(0)\n",
        "Image(os.path.join(sample_dir, 'fake_images-0000.png'))"
      ],
      "metadata": {
        "id": "3cZyBU6ODS8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train GAN for given no.of epochs\n",
        "num_epochs = 3\n",
        "total_step = len(train_dl)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, classes) in enumerate(train_dl):\n",
        "      if i==20:\n",
        "        break\n",
        "      d_loss = train_discriminator(images, classes)\n",
        "      g_loss = train_generator(classes)\n",
        "    print('Epoch [{}/{}], Step [{}/{}], d_loss: {:.4f}, g_loss: {:.4f}' .format(epoch+1, num_epochs, i+1, total_step, d_loss.item(), g_loss.item()))\n",
        "    save_fake_images(epoch+1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPYnu7_dnsHr",
        "outputId": "eb92507c-a025-4bc1-eda7-9cb3cee0fdfc"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/3], Step [21/500], d_loss: 5.9604, g_loss: 2.9905\n",
            "Saving fake_images-0001.png\n",
            "Epoch [2/3], Step [21/500], d_loss: 5.8171, g_loss: 2.8500\n",
            "Saving fake_images-0002.png\n",
            "Epoch [3/3], Step [21/500], d_loss: 5.5792, g_loss: 3.3870\n",
            "Saving fake_images-0003.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CODE BLOCK TO CREATE VIDEO OF TRAINING\n",
        "import cv2\n",
        "from IPython.display import FileLink\n",
        "\n",
        "vid_fname = 'cifar_gans_training.avi'\n",
        "\n",
        "files = [os.path.join(sample_dir, f) for f in os.listdir(sample_dir) if 'fake_images' in f]\n",
        "files.sort()\n",
        "\n",
        "out = cv2.VideoWriter(vid_fname,cv2.VideoWriter_fourcc(*'MP4V'), 8, (302,302))\n",
        "[out.write(cv2.imread(fname)) for fname in files]\n",
        "out.release()\n",
        "FileLink('cifar_gans_training.avi')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "9QELRSTpEpYS",
        "outputId": "711c0502-df61-427e-f105-77a39ba81f6e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "/content/cifar_gans_training.avi"
            ],
            "text/html": [
              "<a href='cifar_gans_training.avi' target='_blank'>cifar_gans_training.avi</a><br>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MS-SSIM"
      ],
      "metadata": {
        "id": "nkDdynknbZ3t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-msssim"
      ],
      "metadata": {
        "id": "1z0gnv47bccb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_msssim import ssim, ms_ssim\n",
        "from torchvision.transforms import Resize\n",
        "# SSIM = [-1,1], MS-SSIM = [0,1] (1 is perfect similarity, 0 is no similarity)\n",
        "\n",
        "\n",
        "# Since image size must be larger than 160\n",
        "# to calculate MS-SSIM (downsampling op)\n",
        "resize = Resize(200, antialias=False)\n",
        "\n",
        "# Between original images and generated image\n",
        "for imgs, classes in train_dl:\n",
        "  X = resize(denorm(imgs))\n",
        "  Y = resize(denorm(G(classes)))\n",
        "  break\n",
        "\n",
        "ssim_score = ssim(X, Y, data_range=1, size_average=True)\n",
        "ms_ssim_score = ms_ssim( X, Y, data_range=1, size_average=True)\n",
        "print('Original and Fake Similarity:')\n",
        "print('SSIM: {0:.3f}; MS-SSIM: {0:.3f}'.format(ssim_score, ms_ssim_score))\n",
        "\n",
        "# Between two sets of generated images (same classes)\n",
        "for imgs, classes in train_dl:\n",
        "  X = resize(G(classes))\n",
        "  Y = resize(G(classes))\n",
        "  break\n",
        "\n",
        "ssim_score = ssim(X, Y, data_range=1, size_average=True)\n",
        "ms_ssim_score = ms_ssim( X, Y, data_range=1, size_average=True)\n",
        "print('Generated Images Similarity:')\n",
        "print('SSIM: {0:.3f}; MS-SSIM: {0:.3f}'.format(ssim_score, ms_ssim_score))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1249E4Xc_tGk",
        "outputId": "be35a9a9-f7d6-4a4b-b4a6-36af0f6a2118"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original and Fake Similarity:\n",
            "SSIM: -0.034; MS-SSIM: -0.034\n",
            "Generated Images Similarity:\n",
            "SSIM: 0.242; MS-SSIM: 0.242\n"
          ]
        }
      ]
    }
  ]
}